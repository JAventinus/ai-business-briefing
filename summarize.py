"""
summarize.py  ‚Äì  baut Podcast-Skript aus articles.json
‚Ä¢ Prim√§r: GPT-4o-mini  (ca. 2 000 W√∂rter, 15-20 min Audio)
‚Ä¢ Fallback 1: GPT-3.5-turbo-16k    (k√ºrzer, ~1 200 W√∂rter)
‚Ä¢ Fallback 2: Mini-Hinweistext     (falls alle Quoten ersch√∂pft)
"""

import json, os, sys, openai, time
from pathlib import Path

PRIMARY_MODEL   = "gpt-4o-mini"
SECONDARY_MODEL = "gpt-3.5-turbo-16k"
TOKENS_PRIMARY  = 2_800     # ~2 000 W√∂rter
TOKENS_SECOND   = 1_500
TEMP            = 0.4

TEMPLATE = """\
Du bist Redakteur eines deutschsprachigen Podcasts √ºber KI-Gesch√§ftsmodelle.
Nutze die Quellen, um eine ca. {words} W√∂rter lange Episode zu schreiben:

# Headline
## Intro ‚Äì 4-5 S√§tze
### Top-Stories
### Deep-Dive
### Take-aways
### Call-to-Action
"""

FALLBACK = """\
# AI Business Briefing
## Intro
Heute liegen keine neuen, relevanten Meldungen zu KI-Gesch√§ftsmodellen vor ‚Äì \
wir melden uns morgen wieder mit frischen Nachrichten.
"""

def load_articles() -> list[dict]:
    if not Path("articles.json").is_file():
        return []
    return json.loads(Path("articles.json").read_text())

def build_prompt(arts: list[dict], words: int) -> str:
    bullets = "\n".join(f"- {a['title']} ({a['url']})" for a in arts[:12])
    return TEMPLATE.format(words=words) + "\n\nQUELLEN HEUTE:\n" + bullets

def call_openai(model: str, prompt: str, tokens: int) -> str | None:
    try:
        resp = openai.chat.completions.create(
            model=model,
            messages=[{"role": "system", "content": prompt}],
            max_tokens=tokens,
            temperature=TEMP,
        )
        return resp.choices[0].message.content.strip()
    except openai.RateLimitError as e:
        print(f"‚ö†Ô∏è  RateLimit ({model}): {e}")
        return None
    except Exception as e:
        print(f"‚ùå  Fehler ({model}): {e}")
        return None

def main():
    arts = load_articles()
    openai.api_key = os.getenv("OPENAI_API_KEY") or sys.exit("OPENAI_API_KEY fehlt")

    if not arts:
        Path("script.txt").write_text(FALLBACK)
        print("‚ÑπÔ∏è  Keine Artikel ‚Äì Fallback-Text geschrieben.")
        return

    # --- Hauptversuch mit GPT-4o-mini
    txt = call_openai(
        PRIMARY_MODEL,
        build_prompt(arts, 2000),
        TOKENS_PRIMARY
    )
    if txt:
        Path("script.txt").write_text(txt)
        print(f"‚úÖ  GPT-4o-Skript geschrieben ({len(txt.split())} W√∂rter)")
        return

    # --- Zweiter Versuch mit GPT-3.5-turbo-16k
    print("üîÑ  Versuche GPT-3.5-turbo-16k ‚Ä¶")
    txt = call_openai(
        SECONDARY_MODEL,
        build_prompt(arts, 1200),
        TOKENS_SECOND
    )
    if txt:
        Path("script.txt").write_text(txt)
        print(f"‚úÖ  GPT-3.5-Skript geschrieben ({len(txt.split())} W√∂rter)")
        return

    # --- Letzter Fallback
    Path("script.txt").write_text(FALLBACK)
    print("‚ö†Ô∏è  Beide Modelle nicht verf√ºgbar ‚Äì Kurzfassung geschrieben.")

if __name__ == "__main__":
    main()
